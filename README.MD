# Proyecto de AceleraciÃ³n de Inferencia en Edge (NVIDIA Jetson)
![Platform](https://img.shields.io/badge/Platform-NVIDIA_Jetson_Orin_NX-green) ![Language](https://img.shields.io/badge/Language-C++_17_%7C_CUDA-blue) ![Tools](https://img.shields.io/badge/Scripting-Python_3.x-yellow) ![Framework](https://img.shields.io/badge/AI-TensorRT_10_%7C_OpenCV-orange)

## ðŸš§ Estado del Proyecto: Fase Inicial (OptimizaciÃ³n de Hardware)

**Nota Importante:** Este repositorio representa la **primera fase de un proyecto a largo plazo**.

Actualmente, el objetivo principal **no es la precisiÃ³n (accuracy) del modelo**, sino la **velocidad de inferencia y la optimizaciÃ³n del pipeline** en hardware embebido (NVIDIA Jetson). Es posible que notes que el modelo comete errores en la detecciÃ³n o clasificaciÃ³n; esto es esperado, ya que el entrenamiento exhaustivo se realizarÃ¡ en una etapa posterior. Ahora mismo, nuestra prioridad es reducir la latencia, maximizar los FPS y asegurar que la integraciÃ³n con CUDA y TensorRT funcione correctamente.

## DescripciÃ³n General

Este proyecto implementa un sistema de visiÃ³n por computadora optimizado para dispositivos de borde (Edge AI) para la detecciÃ³n de cÃ©lulas. Hemos migrado la lÃ³gica de inferencia a C++ y CUDA para aprovechar al mÃ¡ximo el hardware de la Jetson.

### Â¿Por quÃ© decidimos hacerlo asÃ­?

1. **C++ & CUDA Nativo:** A diferencia de una implementaciÃ³n pura en Python, aquÃ­ utilizamos C++ para la lÃ³gica principal y kernels de CUDA (`preprocess.cu`) para el pre-procesamiento de imÃ¡genes. Esto libera al CPU de tareas pesadas como la normalizaciÃ³n y redimensionamiento.
    
2. **TensorRT:** El modelo ONNX se convierte a un motor serializado (`.engine`) optimizado especÃ­ficamente para la GPU de la Jetson, permitiendo fusiÃ³n de capas y precisiÃ³n FP16.
    
3. **SeparaciÃ³n de Responsabilidades:** Tenemos ejecutables dedicados para benchmarking, demostraciÃ³n visual y ejecuciÃ³n en CPU para benchmarking.
    

## Estructura del Proyecto

La organizaciÃ³n actual del repositorio es la siguiente:

```
.
â”œâ”€â”€ build/                  # Archivos compilados y artefactos
â”‚   â”œâ”€â”€ cancer_benchmark    # Ejecutable para pruebas de rendimiento
â”‚   â”œâ”€â”€ cancer_demo         # Ejecutable para demostraciÃ³n visual
â”‚   â”œâ”€â”€ cancer_hpc          # Ejecutable principal optimizado
â”‚   â””â”€â”€ cancer_detector.engine # Motor TensorRT generado (runtime)
â”œâ”€â”€ CMakeLists.txt          # ConfiguraciÃ³n de compilaciÃ³n CMake
â”œâ”€â”€ data/                   # Datos de prueba
â”‚   â”œâ”€â”€ pruebas/            # ImÃ¡genes BMP para validaciÃ³n
â”‚   â””â”€â”€ test_cell.jpg       # Imagen de prueba unitaria
â”œâ”€â”€ include/                # Cabeceras
â”‚   â””â”€â”€ preprocess.h        # DefiniciÃ³n de funciones de preprocesamiento
â”œâ”€â”€ models/                 # Modelos de red neuronal
â”‚   â”œâ”€â”€ cancer_detector_norm.onnx      # Modelo exportado
â”‚   â””â”€â”€ cancer_detector_norm.onnx.data # Pesos del modelo ONNX
â”œâ”€â”€ README.MD               # Este archivo
â”œâ”€â”€ scripts/                # Scripts auxiliares
â”‚   â””â”€â”€ benchmark_cpu.py    # Comparativa de rendimiento en CPU (Python)
â””â”€â”€ src/                    # CÃ³digo fuente
    â”œâ”€â”€ main.cpp            # LÃ³gica para 'cancer_hpc'
    â”œâ”€â”€ main_benchmark.cpp  # LÃ³gica para 'cancer_benchmark'
    â”œâ”€â”€ main_demo.cpp       # LÃ³gica para 'cancer_demo'
    â””â”€â”€ preprocess.cu       # Kernels CUDA para pre-procesamiento de imÃ¡genes
```

### Detalle de los componentes clave

- **`src/preprocess.cu`**: Contiene kernels CUDA personalizados. En lugar de usar OpenCV en CPU para redimensionar y normalizar las imÃ¡genes, lo hacemos directamente en la GPU, reduciendo la latencia de transferencia de memoria.
    
    
- **`src/main_demo.cpp` (cancer_demo)**: Incluye visualizaciÃ³n con OpenCV (`imshow`) para dibujar las cajas delimitadoras (bounding boxes) sobre las detecciones.
    

## Requisitos Previos

- **Hardware:** NVIDIA Jetson (Nano, TX2, Xavier, Orin).
    
- **Sistema Operativo:** JetPack 5.x o 6.x (Ubuntu 20.04/22.04).
    
- **LibrerÃ­as:**
    
    - CUDA Toolkit
        
    - TensorRT
        
    - OpenCV (con soporte CUDA recomendado)
        
    - CMake
        

## CompilaciÃ³n e InstalaciÃ³n

1. **Crear directorio de construcciÃ³n:**
    
    ```
    mkdir build
    cd build
    ```
    
2. **Configurar y Compilar:**
    
    ```
    cmake ..
    make -j$(nproc)
    ```
    

Al finalizar, tendrÃ¡s los ejecutables `cancer_hpc`, `cancer_demo` y `cancer_benchmark` dentro de la carpeta `build/`.

## EjecuciÃ³n

### 1. GeneraciÃ³n del Motor (Engine)

El cÃ³digo espera leer un archivo `.engine`. Si aÃºn no lo tienes generado en `build/`, debes crearlo a partir del ONNX usando `trtexec`:

```
# Ejecutar desde la carpeta build/
/usr/src/tensorrt/bin/trtexec \
  --onnx=../models/cancer_detector_norm.onnx \
  --saveEngine=cancer_detector.engine \
  --fp16
```

### 2. Modos de Uso

A. Modo Demo (VisualizaciÃ³n):

Para ver las detecciones en pantalla.

```
./cancer_demo
```

Esto abrirÃ¡ una ventana mostrando las cÃ©lulas detectadas sobre las imÃ¡genes de `data/` o el video input configurado.

B. Benchmarking (Pruebas de EstrÃ©s):

Para medir latencia y FPS.

```
./cancer_benchmark
```

Adicionalmente, puedes comparar contra la implementaciÃ³n de CPU usando el script de Python:

```
python3 ../scripts/benchmark_cpu.py
```

---

##  Roadmap

1. **Fase 1 (Actual):** AceleraciÃ³n de hardware con CUDA/TensorRT en Jetson.
    
2. **Fase 2:** Re-entrenamiento con dataset ampliado para mejorar precisiÃ³n.
    
3. **Fase 3:** OptimizaciÃ³n INT8 y calibraciÃ³n.
    
4. **Fase 4:** Despliegue en entorno clÃ­nico.
    
---
**Autores:** Alison Celeste Morales Jaramillo, Alonso Delfino Cervantes Flores, Nadia Paulina RamÃ­rez CristÃ³bal
**Fecha:** Diciembre 2025
**Licencia:** MIT
*Proyecto desarrollado para la clase de High Performance Computing en sistemas embebidos de NVIDIA (2025-1), impartido por **D.Sc. JosÃ© Eduardo Chairez Veloz** *
