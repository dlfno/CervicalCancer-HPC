# Proyecto de Aceleraci√≥n de Inferencia en Edge (NVIDIA Jetson)
![Platform](https://img.shields.io/badge/Platform-NVIDIA_Jetson_Orin_NX-green) ![Language](https://img.shields.io/badge/Language-C++_17_%7C_CUDA-blue) ![Tools](https://img.shields.io/badge/Scripting-Python_3.x-yellow) ![Framework](https://img.shields.io/badge/AI-TensorRT_10_%7C_OpenCV-orange)

## üöß Estado del Proyecto: Fase Inicial (Optimizaci√≥n de Hardware)

**Nota Importante:** Este repositorio representa la **primera fase de un proyecto a largo plazo**.

Actualmente, el objetivo principal **no es la precisi√≥n (accuracy) del modelo**, sino la **velocidad de inferencia y la optimizaci√≥n del pipeline** en hardware embebido (NVIDIA Jetson). Es posible que notes que el modelo comete errores en la detecci√≥n o clasificaci√≥n; esto es esperado, ya que el entrenamiento exhaustivo se realizar√° en una etapa posterior. Ahora mismo, nuestra prioridad es reducir la latencia, maximizar los FPS y asegurar que la integraci√≥n con CUDA y TensorRT funcione correctamente.

## Descripci√≥n General

Este proyecto implementa un sistema de visi√≥n por computadora optimizado para dispositivos de borde (Edge AI) para la detecci√≥n de c√©lulas. Hemos migrado la l√≥gica de inferencia a C++ y CUDA para aprovechar al m√°ximo el hardware de la Jetson.

### ¬øPor qu√© decidimos hacerlo as√≠?

1. **C++ & CUDA Nativo:** A diferencia de una implementaci√≥n pura en Python, aqu√≠ utilizamos C++ para la l√≥gica principal y kernels de CUDA (`preprocess.cu`) para el pre-procesamiento de im√°genes. Esto libera al CPU de tareas pesadas como la normalizaci√≥n y redimensionamiento.
    
2. **TensorRT:** El modelo ONNX se convierte a un motor serializado (`.engine`) optimizado espec√≠ficamente para la GPU de la Jetson, permitiendo fusi√≥n de capas y precisi√≥n FP16.
    
3. **Separaci√≥n de Responsabilidades:** Tenemos ejecutables dedicados para benchmarking, demostraci√≥n visual y ejecuci√≥n en CPU para benchmarking.
    

## Estructura del Proyecto

La organizaci√≥n actual del repositorio es la siguiente:

```
.
‚îú‚îÄ‚îÄ build/                  # Archivos compilados y artefactos
‚îÇ   ‚îú‚îÄ‚îÄ cancer_benchmark    # Ejecutable para pruebas de rendimiento
‚îÇ   ‚îú‚îÄ‚îÄ cancer_demo         # Ejecutable para demostraci√≥n visual
‚îÇ   ‚îú‚îÄ‚îÄ cancer_hpc          # Ejecutable principal optimizado
‚îÇ   ‚îî‚îÄ‚îÄ cancer_detector.engine # Motor TensorRT generado (runtime)
‚îú‚îÄ‚îÄ CMakeLists.txt          # Configuraci√≥n de compilaci√≥n CMake
‚îú‚îÄ‚îÄ data/                   # Datos de prueba
‚îÇ   ‚îú‚îÄ‚îÄ pruebas/            # Im√°genes BMP para validaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ test_cell.jpg       # Imagen de prueba unitaria
‚îú‚îÄ‚îÄ include/                # Cabeceras
‚îÇ   ‚îî‚îÄ‚îÄ preprocess.h        # Definici√≥n de funciones de preprocesamiento
‚îú‚îÄ‚îÄ models/                 # Modelos de red neuronal
‚îÇ   ‚îú‚îÄ‚îÄ cancer_detector_norm.onnx      # Modelo exportado
‚îÇ   ‚îî‚îÄ‚îÄ cancer_detector_norm.onnx.data # Pesos del modelo ONNX
‚îú‚îÄ‚îÄ README.MD               # Este archivo
‚îú‚îÄ‚îÄ scripts/                # Scripts auxiliares
‚îÇ   ‚îî‚îÄ‚îÄ benchmark_cpu.py    # Comparativa de rendimiento en CPU (Python)
‚îî‚îÄ‚îÄ src/                    # C√≥digo fuente
    ‚îú‚îÄ‚îÄ main.cpp            # L√≥gica para 'cancer_hpc'
    ‚îú‚îÄ‚îÄ main_benchmark.cpp  # L√≥gica para 'cancer_benchmark'
    ‚îú‚îÄ‚îÄ main_demo.cpp       # L√≥gica para 'cancer_demo'
    ‚îî‚îÄ‚îÄ preprocess.cu       # Kernels CUDA para pre-procesamiento de im√°genes
```

    

## Requisitos Previos

- **Hardware:** NVIDIA Jetson (Nano, TX2, Xavier, Orin).
    
- **Sistema Operativo:** JetPack 5.x o 6.x (Ubuntu 20.04/22.04).
    
- **Librer√≠as:**
    
    - CUDA Toolkit
        
    - TensorRT
        
    - OpenCV (con soporte CUDA recomendado)
        
    - CMake
        
---

## Descripci√≥n T√©cnica de M√≥dulos

El proyecto se compone de cuatro piezas fundamentales que separan la l√≥gica de demostraci√≥n, validaci√≥n de rendimiento y optimizaci√≥n de hardware:

### 1. `src/main_demo.cpp` (Validaci√≥n Funcional)
Es el punto de entrada para verificar la **correcci√≥n del sistema**.
* **Funci√≥n:** Carga el motor TensorRT y procesa una imagen individual (`test_cell.jpg`) para simular un diagn√≥stico cl√≠nico en tiempo real.
* **Salida:** Interfaz visual en terminal (CLI) con barras de carga y reporte de probabilidad (Sano/Anomal√≠a). Sirve para demostrar que el pipeline de inferencia funciona correctamente de principio a fin.

### 2. `src/main_benchmark.cpp` (An√°lisis de Rendimiento HPC)
M√≥dulo cr√≠tico dise√±ado para estresar el hardware y obtener m√©tricas puras.
* **Funci√≥n:** Ejecuta un bucle de 1000 iteraciones de inferencia continua sobre la GPU, midiendo el ciclo completo (Host-to-Device transfer + Preprocesamiento + Inferencia + Device-to-Host transfer).
* **Salida:** Calcula y reporta la **Latencia Promedio (ms)** y el **Throughput (FPS)** real del sistema optimizado.

### 3. `src/preprocess.cu` (Aceleraci√≥n por Hardware)
Contiene la implementaci√≥n de bajo nivel necesaria para liberar al CPU.
* **Funci√≥n:** Define `kernels` de CUDA personalizados que se ejecutan directamente en los n√∫cleos de la GPU.
* **Tarea:** Realiza la normalizaci√≥n de p√≠xeles, reordenamiento de canales (HWC a CHW) y escalado de imagen sin mover los datos de la memoria gr√°fica, eliminando cuellos de botella en el bus de memoria.

### 4. `scripts/benchmark_cpu.py` (L√≠nea Base)
Script de Python utilizado para establecer el punto de comparaci√≥n (Baseline).
* **Funci√≥n:** Ejecuta la misma arquitectura neuronal utilizando PyTorch est√°ndar sobre el CPU.
* **Objetivo:** Permite calcular el **Speedup (x veces m√°s r√°pido)** que ofrece nuestra implementaci√≥n en C++/CUDA frente a una implementaci√≥n tradicional en software.

### 5. `include/preprocess.h` (El Puente C++/CUDA)
Es el archivo de cabecera que conecta dos mundos distintos.
* **Funci√≥n:** Act√∫a como interfaz o "contrato" entre el c√≥digo C++ est√°ndar y el compilador de NVIDIA (NVCC).
* **Tarea:** Declara la funci√≥n `launchPreprocess`, permitiendo que los ejecutables principales (`main_demo` y `main_benchmark`) puedan invocar los kernels de la GPU sin necesidad de conocer la sintaxis compleja de CUDA.

## Compilaci√≥n e Instalaci√≥n

Sigue estos pasos estrictamente desde la terminal de tu Jetson:

1.  **Clonar el repositorio y acceder a la carpeta:**
    ```bash
    git clone [https://github.com/dlfno/CervicalCancer-HPC.git](https://github.com/dlfno/CervicalCancer-HPC.git)
    cd CervicalCancer-HPC
    ```

2.  **Crear el directorio de construcci√≥n:**
    ```bash
    mkdir -p build
    cd build
    ```

3.  **Compilar el proyecto:**
    ```bash
    cmake ..
    make -j$(nproc)
    ```

> **Nota:** Al finalizar, deber√°s ver los ejecutables `cancer_demo` y `cancer_benchmark` dentro de la carpeta `build/`.

---

## Gu√≠a de Ejecuci√≥n

Todos los comandos deben ejecutarse desde la carpeta `build/` creada en el paso anterior.

### Paso 1: Generar el Motor TensorRT (Solo la primera vez)
El c√≥digo C++ requiere un motor optimizado. Genera el archivo `.engine` a partir del modelo ONNX usando `trtexec`:

```bash
/usr/src/tensorrt/bin/trtexec \
  --onnx=../models/cancer_detector_norm.onnx \
  --saveEngine=cancer_detector.engine \
  --fp16
````

_Si este paso no se realiza, los demos fallar√°n._

### Paso 2: Ejecutar Demo Visual

Muestra el diagn√≥stico simulado en la terminal procesando una imagen de prueba.

Bash

```
./cancer_demo
```

### Paso 3: Benchmark de Rendimiento (HPC)

Mide la latencia y los FPS reales utilizando la GPU + TensorRT.

Bash

```
./cancer_benchmark
```

### Paso 4: Comparativa con CPU 

Para contrastar la velocidad obtenida, ejecuta el script de Python que corre en CPU pura:

Bash

```
python3 ../scripts/benchmark_cpu.py
```

---

##  Roadmap

1. **Fase 1 (Actual):** Aceleraci√≥n de hardware con CUDA/TensorRT en Jetson.
    
2. **Fase 2:** Re-entrenamiento con dataset ampliado para mejorar precisi√≥n.
    
3. **Fase 3:** Optimizaci√≥n INT8 y calibraci√≥n.
    
4. **Fase 4:** Despliegue en entorno cl√≠nico.
    
---
**Autores:** Alison Celeste Morales Jaramillo, Alonso Delfino Cervantes Flores, Nadia Paulina Ram√≠rez Crist√≥bal

**Fecha:** Diciembre 2025

**Licencia:** MIT

_Proyecto desarrollado para la clase de High Performance Computing en sistemas embebidos de NVIDIA (2025-1), impartido por **D.Sc. Jos√© Eduardo Chairez Veloz**_
